{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "rcParams = {'font.size': 24 , 'font.weight': 'normal', 'font.family': 'sans-serif',\n",
    "            'axes.unicode_minus':False, 'axes.labelweight':'normal'}\n",
    "plt.rcParams.update(rcParams)\n",
    "\n",
    "def Load_PAF(filepath):\n",
    "    lines = open(filepath).readlines()\n",
    "    header = ['Query','Qlen','QStart','QEnd','Orientation','Subject','SLen',\n",
    "              'SStart','SEnd','Matches','AlignLength','MAPQ']\n",
    "    op = []\n",
    "    for l in lines:\n",
    "        l = l.split('\\t')[:12]\n",
    "        op.append(dict(zip(header, l)))\n",
    "    df = pd.DataFrame(op)\n",
    "    df[['Qlen','QStart','QEnd','SLen','SStart',\n",
    "        'SEnd','Matches','AlignLength','MAPQ']] = df[['Qlen','QStart','QEnd','SLen','SStart',\n",
    "                                                      'SEnd','Matches','AlignLength','MAPQ']].astype('int')\n",
    "    df['PIdent'] = df['AlignLength']/df['Qlen']*100\n",
    "    df = df.loc[df.groupby(['Query'])['PIdent'].idxmax()]\n",
    "    df = df[['Query','Qlen','PIdent']]\n",
    "    df = df.rename(columns = {'Query':'Contig'})\n",
    "    df = df.set_index('Contig')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotspr20Samplet1\n",
      "Hotspr2Sample149\n",
      "HotsprSampleR4cd\n",
      "HotsprSampOS1260\n",
      "HotsprSampleOS50\n",
      "HotsprSampleMS50\n",
      "HotsprSampleOS60\n",
      "HotsprSampleMSe3\n",
      "Hotspr20SampleT9\n",
      "HotsprSampleOS55\n",
      "HotsprSamplt10cd\n",
      "HotsprSampleMSe4\n"
     ]
    }
   ],
   "source": [
    "fdir = '/Users/harihara/Mount/hotspring_metagenome/Synechococcus_paper_analysis/Differential_Read_Counting/'\n",
    "paf = '/Users/harihara/Mount/hotspring_metagenome/Synechococcus_paper_analysis/reassembly/contig_mapping_paf/'\n",
    "\n",
    "files = listdir(fdir)\n",
    "\n",
    "orphaned_reads_counts = {}\n",
    "\n",
    "for f in files:\n",
    "    sample = f.replace(\"_Diff_Read_Count\",\"\")\n",
    "    if f.startswith(\"Hot\"):\n",
    "        print(sample)\n",
    "        df_osa_read_counts = pd.read_csv(fdir+f+'/OSA.Orphaned_Read_Counts', sep = \"\\t\", index_col = 'Contig')\n",
    "        df_osb_read_counts = pd.read_csv(fdir+f+'/OSB.Orphaned_Read_Counts', sep = \"\\t\", index_col = 'Contig')\n",
    "        df_osa_paf = Load_PAF(paf+sample+'_osa_contigs_aligned_to_osa.paf')\n",
    "        df_osb_paf = Load_PAF(paf+sample+'_osb_contigs_aligned_to_osb.paf')\n",
    "        df_osa = df_osa_read_counts.join(df_osa_paf, how = 'left')\n",
    "        df_osa = df_osa.reset_index()\n",
    "        df_osb = df_osb_read_counts.join(df_osb_paf, how = 'left')\n",
    "        df_osb = df_osb.reset_index()\n",
    "        orphaned_reads_counts[sample] = {'OSA':df_osa, 'OSB':df_osb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novel_contigs = pd.read_csv('/Users/harihara/Research-Activities/Data/Hot-Spring/contig_containment_groups_subset.txt', \n",
    "                               sep = '\\t')\n",
    "novel_contig_dict = {}\n",
    "novel_contigs = list(set(df_novel_contigs['Contig'].tolist()))\n",
    "for n in novel_contigs:\n",
    "    splits = n.split('_')\n",
    "    if len(splits) == 4:\n",
    "        sample = splits[0]\n",
    "        genome = splits[1].upper()\n",
    "        contig = splits[2]+'_'+splits[3]\n",
    "    if len(splits) == 5:\n",
    "        sample = splits[0] + '_' +splits[1]\n",
    "        genome = splits[2].upper()\n",
    "        contig = splits[3]+'_'+splits[4]\n",
    "    try:\n",
    "        novel_contig_dict[sample][genome].append(contig)\n",
    "    except KeyError:\n",
    "        novel_contig_dict[sample] = {'OSA':[], 'OSB':[]}\n",
    "        novel_contig_dict[sample][genome].append(contig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_novel_read_counts = pd.DataFrame()\n",
    "df_not_novel_read_counts = pd.DataFrame()\n",
    "\n",
    "for k in novel_contig_dict.keys():\n",
    "    print(k)\n",
    "    osa = orphaned_reads_counts[k]['OSA']\n",
    "    sel_novel = osa.loc[osa['Contig'].isin(novel_contig_dict[k]['OSA'])]\n",
    "    sel_novel['Sample'] = k\n",
    "    sel_novel['Genome'] = 'osa'\n",
    "    df_novel_read_counts = df_novel_read_counts.append(sel_novel, ignore_index = True)\n",
    "    \n",
    "    sel = osa.loc[~osa['Contig'].isin(novel_contig_dict[k]['OSA'])]\n",
    "    sel['Sample'] = k\n",
    "    sel['Genome'] = 'osa'\n",
    "    df_not_novel_read_counts = df_not_novel_read_counts.append(sel, ignore_index = True)\n",
    "    \n",
    "    osb = orphaned_reads_counts[k]['OSB']\n",
    "    sel_novel = osb.loc[osb['Contig'].isin(novel_contig_dict[k]['OSB'])]\n",
    "    sel_novel['Sample'] = k\n",
    "    sel_novel['Genome'] = 'osb'\n",
    "    df_novel_read_counts = df_novel_read_counts.append(sel_novel, ignore_index = True)\n",
    "    \n",
    "    sel = osb.loc[~osb['Contig'].isin(novel_contig_dict[k]['OSB'])]\n",
    "    sel['Sample'] = k\n",
    "    sel['Genome'] = 'osb'\n",
    "    df_not_novel_read_counts = df_not_novel_read_counts.append(sel, ignore_index = True)\n",
    "    \n",
    "df_novel_read_counts['Or_Ratio'] = (df_novel_read_counts['Orphaned_Read_Flag(Aligned)']+\n",
    "                                    df_novel_read_counts['Orphaned_Read_Flag(Non-Aligned)'])/df_novel_read_counts['Read']*100\n",
    "df_not_novel_read_counts['Or_Ratio'] = (df_not_novel_read_counts['Orphaned_Read_Flag(Aligned)']+\n",
    "                                        df_not_novel_read_counts['Orphaned_Read_Flag(Non-Aligned)'])/df_not_novel_read_counts['Read']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(rcParams)\n",
    "min_read_count = 50\n",
    "df_novel_filter = df_novel_read_counts[df_novel_read_counts['Read'] > min_read_count]\n",
    "df_not_novel_filter = df_not_novel_read_counts[(df_not_novel_read_counts['Read'] > min_read_count) & \n",
    "                                               (df_not_novel_read_counts['Qlen'] >= 500) &\n",
    "                                               (df_not_novel_read_counts['PIdent'] >= 80)]\n",
    "print(len(df_novel_read_counts), len(df_novel_filter))\n",
    "print(len(df_not_novel_read_counts), len(df_not_novel_filter))\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize = (16,9))\n",
    "ax[0].hist(df_novel_filter['Or_Ratio'], bins = 35, density = True, cumulative = False, color = 'orange', \n",
    "            histtype = 'step', label = 'Novel Contigs', linewidth = 4)\n",
    "ax[0].hist(df_not_novel_filter['Or_Ratio'], bins = 35, density = True, cumulative = False, color = 'teal', \n",
    "           histtype = 'step', label = 'Non-Novel Contigs', linewidth = 4)\n",
    "ax[0].set_xlabel('Percentage of Orphaned Reads')\n",
    "ax[0].legend()\n",
    "\n",
    "boxprops = dict(linewidth=4, color='blue')\n",
    "ax[1].boxplot([df_not_novel_filter['Or_Ratio'].tolist(), df_novel_filter['Or_Ratio'].tolist()], \n",
    "              whis = [5, 95], boxprops=boxprops, showmeans = True, showfliers = True)\n",
    "ax[1].set_xticklabels(['Non-Novel Contigs', 'Novel Contigs'])\n",
    "ax[1].set_ylabel('Percentage of Orphaned Reads')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('/Users/harihara/Research-Activities/Plots/Hot_Spring_Plots/Synechococcus-Paper/Orphaned_Reads.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-statistic\n",
      "Z-value: 106.07025236845418\n",
      "The difference in orphaned-reads between novel and non-novel contigs are highly significant\n",
      "\n",
      "KS-Test\n",
      "KstestResult(statistic=0.5401114674742081, pvalue=0.0)\n"
     ]
    }
   ],
   "source": [
    "mu_x1 = df_novel_filter['Or_Ratio'].mean()\n",
    "mu_x2 = df_not_novel_filter['Or_Ratio'].mean()\n",
    "\n",
    "sd_x1 = df_novel_filter['Or_Ratio'].std()/(len(df_novel_filter)**0.5)\n",
    "sd_x2 = df_not_novel_filter['Or_Ratio'].std()/(len(df_not_novel_filter)**0.5)\n",
    "\n",
    "z = (mu_x1 - mu_x2)/(sd_x1**2 + sd_x2**2)**0.5\n",
    "\n",
    "print('Z-statistic')\n",
    "if z >= 3.0:\n",
    "    print('Z-value:',z)\n",
    "    print('The difference in orphaned-reads between novel and non-novel contigs are highly significant')\n",
    "elif z >= 2.5 and z < 3.0:\n",
    "    print('Z-value:',z)\n",
    "    print('The difference in orphaned-reads between novel and non-novel contigs are significant')\n",
    "elif z >= 2.0 and z < 2.5:\n",
    "    print('Z-value:',z)\n",
    "    print('The difference in orphaned-reads between novel and non-novel contigs are marginally significant')  \n",
    "elif z < 3.0:\n",
    "    print('Z-value:',z)\n",
    "    print('The difference in orphaned-reads between novel and non-novel contigs are insignificant')\n",
    "\n",
    "print('\\nKS-Test')\n",
    "print(ks_2samp(df_novel_read_counts['Or_Ratio'], df_not_novel_read_counts['Or_Ratio']))\n",
    "\n",
    "###The two distributions are very different "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
