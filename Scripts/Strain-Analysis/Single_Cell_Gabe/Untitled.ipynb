{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from os import listdir, mkdir\n",
    "\n",
    "rcParams = {'font.size': 30, 'font.weight': 'normal', 'font.family': 'sans-serif',\n",
    "            'axes.unicode_minus':False, 'axes.labelweight':'normal'}\n",
    "\n",
    "plt.rcParams.update(rcParams)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "def Load_PAF(filepath, sample):\n",
    "    header = ['Query','QLen','QStart','QEnd','Orientation','Subject','SLen','SStart','SEnd',\n",
    "              'Matches','AlignLength','MAPQ','TP', 'MM', 'GN', 'GO', 'CG', 'CS']\n",
    "    df = pd.read_csv(filepath, sep = \"\\t\", names = header)\n",
    "    df[['QLen','QStart','QEnd','SLen','SStart',\n",
    "        'SEnd','Matches','AlignLength','MAPQ']] = df[['QLen','QStart','QEnd','SLen','SStart',\n",
    "                                                      'SEnd','Matches','AlignLength','MAPQ']].astype('int')\n",
    "    df['PIdent'] = df['Matches']/df['AlignLength']*100.0\n",
    "    df['Sample'] = sample.replace(\"_FD.paf\",\"\")\n",
    "    df['S_Align'] = df['SEnd'] - df['SStart']\n",
    "    \n",
    "    df = df[(df['QLen'] == df['AlignLength'])]\n",
    "\n",
    "    df['Read_Name'] = df['Query'].str[0:-2]\n",
    "    df['Read_Tag'] = df['Query'].str[-1]\n",
    "    df['MisMatches'] = df['AlignLength']-df['Matches']\n",
    "    df['Read_ID'] = df['Sample']+\"_\"+df['Query']\n",
    "    \n",
    "    return df\n",
    "\n",
    "def Coverage_Stats(group, slen, pe = False):\n",
    "    coverage = np.zeros(slen)\n",
    "    \n",
    "    if (pe):\n",
    "        Sstarts = group[('SStart','1')].tolist() + group[('SStart','2')].tolist()\n",
    "        Sends = group[('SEnd','1')].tolist() + group[('SEnd','2')].tolist()\n",
    "    else:\n",
    "        Sstarts = group['SStart'].tolist()\n",
    "        Sends = group['SEnd'].tolist()\n",
    "    \n",
    "    for i in range(0, len(Sstarts)):\n",
    "        start, end = Sstarts[i], Sends[i]\n",
    "        coverage[start:end] += 1\n",
    "    length = len(coverage)\n",
    "    avg_depth = coverage.sum()\n",
    "    breadth = len(coverage[coverage > 0])/length*100.0\n",
    "    num_reads = len(group)\n",
    "    \n",
    "    return pd.Series({'Avg_Depth_Coverage':avg_depth, \n",
    "                      'Breadth_Coverage':breadth, \n",
    "                      'Num_Reads':num_reads})\n",
    "\n",
    "def Return_Best_Alignment(grp):\n",
    "    Mismatches = np.array(grp['MisMatches'].tolist())\n",
    "    min_mismatch = Mismatches.min()\n",
    "    out = grp[grp['MisMatches'] == min_mismatch]\n",
    "    if len(out) > 1: out['Only'] = False\n",
    "    else: out['Only'] = True\n",
    "    return out\n",
    "\n",
    "def Process_CS_String(CS, v):\n",
    "    vec = np.ones(int(v))\n",
    "    index = 0\n",
    "    CS = CS.replace(\"cs:Z:\",\"\").replace(\"*\",\":\").replace(\"+\",\"&\").replace(\"-\",'&')\n",
    "    splits = CS.split(\":\")\n",
    "    for s in splits[1:]:\n",
    "        r = s.split(\"&\")\n",
    "        if r[0].isnumeric(): \n",
    "            vec[index:index+int(r[0])] = 0\n",
    "            index += int(r[0])\n",
    "        else: index += 1\n",
    "    assert len(vec) == v, \"Length Mismatch\"\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def Count_MisMatches_Paired_End(row, slen=2000):\n",
    "    coverage = np.zeros(slen)\n",
    "    SStart_1, SEnd_1, Orientation_Fow = row[('SStart','1')], row[('SEnd','1')], row[('Orientation','1')]\n",
    "    SStart_2, SEnd_2, Orientation_Rev = row[('SStart','2')], row[('SEnd','2')], row[('Orientation','2')]\n",
    "    CS_1, CS_2 = row[('CS','1')], row[('CS','2')]\n",
    "    V1, V2 = Process_CS_String(CS_1, SEnd_1-SStart_1), Process_CS_String(CS_2, SEnd_2-SStart_2)\n",
    "    \n",
    "    if Orientation_Fow == '+': coverage[SStart_1:SEnd_1] += V1\n",
    "    elif Orientation_Fow == '-': coverage[SStart_1:SEnd_1] += V1[::-1]\n",
    "        \n",
    "    if Orientation_Rev == '+': coverage[SStart_2:SEnd_2] += V2\n",
    "    elif Orientation_Rev == '-': coverage[SStart_2:SEnd_2] += V2[::-1]\n",
    "    \n",
    "    return len(coverage[coverage > 0])\n",
    "    \n",
    "def Merge_Paired_Ends(df_all):\n",
    "    df = df_all.pivot_table(index = ['Subject','Read_Name'], columns = ['Read_Tag'], aggfunc = 'first',\n",
    "                            values = ['SStart','SEnd','MisMatches','CS','Orientation'])\n",
    "    df = df.dropna()\n",
    "    df[[('SStart','1'),('SStart','2'),\n",
    "        ('SEnd','1'),('SEnd','2')]] = df[[('SStart','1'),('SStart','2'),\n",
    "                                          ('SEnd','1'),('SEnd','2')]].astype(int)\n",
    "    df['Overlap'] = (df[[('SStart','1'),('SStart','2')]].max(axis = 1) - \n",
    "                     df[[('SEnd','1'),('SEnd','2')]].min(axis = 1))\n",
    "    df['Overlap_Flag'] = False\n",
    "    df.loc[df['Overlap'] < 0, 'Overlap_Flag'] = True\n",
    "    df['MisMatches_Total'] = df.apply(Count_MisMatches_Paired_End, args=(2000,), axis = 1)\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filedir = '/Users/harihara/Mount-2/hotspring_metagenome/single_cell_analysis_with_Gabe_Birzu/16S_Read_Alignments/'\n",
    "samples = listdir(filedir+'Alpha_Alleles/paf_files/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all_abundances = pd.DataFrame()\n",
    "df_paired_end_read_abundances = pd.DataFrame()\n",
    "\n",
    "for s in samples:\n",
    "    df_alpha = Load_PAF(filedir+'Alpha_Alleles/paf_files/'+s, s)\n",
    "    df_beta = Load_PAF(filedir+'Beta_Alleles/paf_files/'+s, s)\n",
    "    df_gamma = Load_PAF(filedir+'Gamma_Alleles/paf_files/'+s, s)\n",
    "    \n",
    "    Temp = pd.DataFrame()\n",
    "    Temp = Temp.append(df_alpha).append(df_beta).append(df_gamma)\n",
    "    \n",
    "    df_all_abundances = df_all_abundances.append(Temp, ignore_index = True)\n",
    "    df_paired_end = Merge_Paired_Ends(Temp)\n",
    "    df_paired_end['Sample'] = s.replace(\"_FD.paf\",\"\")\n",
    "    \n",
    "    df_paired_end_read_abundances = df_paired_end_read_abundances.append(df_paired_end.reset_index())\n",
    "\n",
    "    print(s, len(Temp), len(df_paired_end)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
